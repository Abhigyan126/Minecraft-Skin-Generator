{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10607544,"sourceType":"datasetVersion","datasetId":6566528},{"sourceId":244938,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":209259,"modelId":230946},{"sourceId":245393,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":209663,"modelId":231355},{"sourceId":245958,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":210171,"modelId":231865}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\n\nclass MinecraftImageDataset(Dataset):\n    def __init__(self, folder_path, img_size=64):\n        \"\"\"\n        Custom Dataset to load valid images from a directory.\n        Args:\n            folder_path (str): Path to the folder containing images.\n            img_size (int): Target size to resize images (img_size x img_size).\n        \"\"\"\n        self.folder_path = folder_path\n        self.image_paths = self._filter_valid_images(folder_path)\n        self.transform = transforms.Compose([\n            transforms.Resize((img_size, img_size)),  # Resize images\n            transforms.ToTensor(),                    # Convert to tensor\n            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n        ])\n\n        print(f\"Total valid images: {len(self.image_paths)}\")  # Print the number of valid images\n\n    def _filter_valid_images(self, folder_path):\n        \"\"\"\n        Filters out invalid or corrupted images from the directory.\n        Args:\n            folder_path (str): Path to the folder containing images.\n\n        Returns:\n            List[str]: List of valid image paths.\n        \"\"\"\n        valid_images = []\n        for img in os.listdir(folder_path):\n            if img.endswith(('.png', '.jpg', '.jpeg')):  # Check for valid extensions\n                img_path = os.path.join(folder_path, img)\n                try:\n                    # Attempt to open and verify the image\n                    with Image.open(img_path) as image:\n                        image.verify()  # Check if the image is valid\n                    valid_images.append(img_path)\n                except Exception as e:\n                    print(f\"Invalid image: {img_path} - {e}\")  # Log invalid image details\n        return valid_images\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')  # Ensure 3-channel RGB\n        return self.transform(image)  # Apply transformations\n\n\ndef load_minecraft_data(folder_path, img_size=64, batch_size=32, shuffle=True):\n    \"\"\"\n    Creates a DataLoader for the Minecraft images with validation.\n    Args:\n        folder_path (str): Path to the folder containing images.\n        img_size (int): Target size to resize images (img_size x img_size).\n        batch_size (int): Number of images per batch.\n        shuffle (bool): Whether to shuffle the dataset.\n\n    Returns:\n        DataLoader: Torch DataLoader for the dataset.\n    \"\"\"\n    dataset = MinecraftImageDataset(folder_path, img_size=img_size)\n    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:22:23.033546Z","iopub.execute_input":"2025-01-31T04:22:23.033870Z","iopub.status.idle":"2025-01-31T04:22:32.237751Z","shell.execute_reply.started":"2025-01-31T04:22:23.033842Z","shell.execute_reply":"2025-01-31T04:22:32.236552Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torch.optim as optim\nfrom torchvision.utils import save_image, make_grid\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nimport numpy as np\nfrom skimage.metrics import structural_similarity as ssim_sklearn\n\n\n# Generator Model\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.LeakyReLU(0.2, inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        # If in_channels and out_channels differ, use a 1x1 conv for shortcut\n        self.shortcut = None\n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.shortcut is not None:\n            residual = self.shortcut(residual)\n\n        out += residual\n        out = self.relu(out)\n\n        return out\n\n\nclass Generator(nn.Module):\n    def __init__(self, latent_dim, img_channels):\n        super(Generator, self).__init__()\n        self.init_size = 4  # Initial image size (4x4)\n        self.l1 = nn.Sequential(nn.Linear(latent_dim, 512 * self.init_size ** 2))\n        self.conv_blocks = nn.Sequential(\n            nn.BatchNorm2d(512),\n            nn.Upsample(scale_factor=2),  # 8x8\n            ResidualBlock(512, 256),\n            nn.Upsample(scale_factor=2),  # 16x16\n            ResidualBlock(256, 128),\n            nn.Upsample(scale_factor=2),  # 32x32\n            ResidualBlock(128, 64),\n            nn.Upsample(scale_factor=2),  # 64x64\n            nn.Conv2d(64, img_channels, 3, stride=1, padding=1),\n            nn.Tanh(),\n        )\n\n\n    def forward(self, z):\n        out = self.l1(z)\n        out = out.view(out.shape[0], 512, self.init_size, self.init_size)\n        img = self.conv_blocks(out)\n        return img\n\n# Critic Model (Discriminator)\nclass Critic(nn.Module):\n    def __init__(self, img_channels):\n        super(Critic, self).__init__()\n        def critic_block(in_channels, out_channels):\n            return [\n                nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1),\n                nn.LeakyReLU(0.2, inplace=True),\n            ]\n\n        self.model = nn.Sequential(\n            *critic_block(img_channels, 64),\n            *critic_block(64, 128),\n            *critic_block(128, 256),\n            \n            *critic_block(256, 512),\n            nn.Flatten(),\n            nn.Linear(512 * 4 * 4, 1),  # Output Wasserstein distance\n        )\n\n    def forward(self, img):\n        return self.model(img)\n\n# Gradient Penalty Function\ndef compute_gradient_penalty(critic, real_imgs, fake_imgs, device):\n    \"\"\"Compute the gradient penalty for WGAN-GP.\"\"\"\n    alpha = torch.rand(real_imgs.size(0), 1, 1, 1).to(device)\n    interpolates = (alpha * real_imgs + (1 - alpha) * fake_imgs).requires_grad_(True)\n    d_interpolates = critic(interpolates)\n    fake = torch.ones(real_imgs.size(0), 1).to(device)\n\n    gradients = torch.autograd.grad(\n        outputs=d_interpolates,\n        inputs=interpolates,\n        grad_outputs=fake,\n        create_graph=True,\n        retain_graph=True,\n        only_inputs=True,\n    )[0]\n\n    gradients = gradients.view(gradients.size(0), -1)\n    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n    return gradient_penalty\n\n# WGAN Training\ndef train_wgan(generator, critic, dataloader, latent_dim, epochs, sample_interval=1, lambda_gp=10):\n    optimizer_G = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n    optimizer_C = optim.Adam(critic.parameters(), lr=0.0001, betas=(0.5, 0.999))\n\n    g_losses, c_losses, ssim_scores = [], [], []\n\n    for epoch in range(epochs):\n        g_loss_epoch, c_loss_epoch = 0.0, 0.0\n        epoch_ssim_scores = []\n\n        for i, imgs in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")):\n            real_imgs = imgs.to(device)\n            batch_size = real_imgs.size(0)\n\n            # Train Critic\n            optimizer_C.zero_grad()\n            z = torch.randn(batch_size, latent_dim).to(device)\n            fake_imgs = generator(z)\n            real_loss = torch.mean(critic(real_imgs))\n            fake_loss = torch.mean(critic(fake_imgs))\n            gradient_penalty = compute_gradient_penalty(critic, real_imgs, fake_imgs, device)\n            c_loss = fake_loss - real_loss + lambda_gp * gradient_penalty\n            c_loss.backward()\n            optimizer_C.step()\n            c_loss_epoch += c_loss.item()\n\n            # Train Generator every n_critic steps\n            if i % 5 == 0:\n                optimizer_G.zero_grad()\n                z = torch.randn(batch_size, latent_dim).to(device)\n                gen_imgs = generator(z)\n                g_loss = -torch.mean(critic(gen_imgs))\n                g_loss.backward()\n                optimizer_G.step()\n                g_loss_epoch += g_loss.item()\n\n                # Calculate SSIM periodically\n                ssim_score = calculate_ssim(real_imgs, gen_imgs)\n                epoch_ssim_scores.append(ssim_score)\n\n        # Record losses and SSIM\n        g_losses.append(g_loss_epoch / len(dataloader))\n        c_losses.append(c_loss_epoch / len(dataloader))\n        ssim_scores.append(np.mean(epoch_ssim_scores))\n\n        # Save sample images\n        if (epoch + 1) % sample_interval == 0:\n            display_sample_images(generator, latent_dim)\n\n        print(f\"[Epoch {epoch + 1}] Generator Loss: {g_losses[-1]:.4f}, Critic Loss: {c_losses[-1]:.4f}, SSIM: {ssim_scores[-1]:.4f}\")\n\n    # Plot losses and SSIM\n    plot_losses_and_ssim(g_losses, c_losses, ssim_scores)\n\n# Display and Plot Functions\ndef display_sample_images(generator, latent_dim):\n    generator.eval()\n    z = torch.randn(16, latent_dim).to(device)\n    gen_imgs = generator(z).detach().cpu()\n    gen_imgs = (gen_imgs + 1) / 2  # Rescale to [0, 1]\n    grid = make_grid(gen_imgs, nrow=4)\n    plt.imshow(grid.permute(1, 2, 0))\n    plt.axis(\"off\")\n    plt.show()\n    generator.train()\n\ndef plot_losses_and_ssim(g_losses, c_losses, ssim_scores):\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n    \n    # Loss plot\n    ax1.plot(g_losses, label=\"Generator Loss\")\n    ax1.plot(c_losses, label=\"Critic Loss\")\n    ax1.set_xlabel(\"Epoch\")\n    ax1.set_ylabel(\"Loss\")\n    ax1.legend()\n    \n    # SSIM plot\n    ax2.plot(ssim_scores, label=\"SSIM Score\", color='green')\n    ax2.set_xlabel(\"Epoch\")\n    ax2.set_ylabel(\"SSIM\")\n    ax2.legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \ndef calculate_ssim(real_imgs, gen_imgs, win_size=3):\n    \"\"\"\n    Calculate SSIM between real and generated images\n    \n    Args:\n    real_imgs (torch.Tensor): Real image batch\n    gen_imgs (torch.Tensor): Generated image batch\n    win_size (int): Window size for SSIM calculation (should be smaller than the image size)\n    \n    Returns:\n    float: Average SSIM score\n    \"\"\"\n    # Convert images to numpy for SSIM calculation\n    real_np = real_imgs.detach().cpu().numpy().transpose(0, 2, 3, 1)\n    gen_np = gen_imgs.detach().cpu().numpy().transpose(0, 2, 3, 1)\n    \n    # Normalize images to [0, 1] range\n    real_np = (real_np + 1) / 2\n    gen_np = (gen_np + 1) / 2\n    \n    # Compute SSIM for each image with custom window size and data_range specified\n    ssim_scores = [ssim_sklearn(real_np[i], gen_np[i], multichannel=True, win_size=win_size, data_range=1.0) \n                   for i in range(len(real_np))]\n    \n    return np.mean(ssim_scores)\n\n# Hyperparameters and Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlatent_dim = 128\nimg_channels = 3\nimg_size = 64\nepochs = 500\nbatch_size = 64\nlambda_gp = 15\n\ngenerator = Generator(latent_dim, img_channels).to(device)\ncritic = Critic(img_channels).to(device)\n\ndata_path = \"/kaggle/input/minecraft-10000-skins\"  # Replace with your dataset directory\ndataloader = load_minecraft_data(data_path, img_size=img_size, batch_size=batch_size)\n    \n    # Initialize and Train WGAN\ntrain_wgan(generator, critic, dataloader, latent_dim, epochs, sample_interval=5, lambda_gp=lambda_gp)\ntorch.save(generator.state_dict(), f\"generator_epoch_{epochs}.pth\")\ntorch.save(critic.state_dict(), f\"critic_epoch_{epochs}.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:23:59.782155Z","iopub.execute_input":"2025-01-31T04:23:59.782756Z","iopub.status.idle":"2025-01-31T04:24:00.462968Z","shell.execute_reply.started":"2025-01-31T04:23:59.782720Z","shell.execute_reply":"2025-01-31T04:24:00.461951Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'data_path = \"/kaggle/input/minecraft-10000-skins\"  # Replace with your dataset directory\\ndataloader = load_minecraft_data(data_path, img_size=img_size, batch_size=batch_size)\\n    \\n    # Initialize and Train WGAN\\ntrain_wgan(generator, critic, dataloader, latent_dim, epochs, sample_interval=5, lambda_gp=lambda_gp)\\ntorch.save(generator.state_dict(), f\"generator_epoch_{epochs}.pth\")\\ntorch.save(critic.state_dict(), f\"critic_epoch_{epochs}.pth\")'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import torch\nfrom torchvision.utils import save_image\nimport os\n\n# Load the saved model weights\ngenerator.load_state_dict(torch.load(\"/kaggle/input/epoch-500-0.0001-2x-db-15-sample-10000/pytorch/v1/1/generator_epoch_500.pth\", map_location=device))\ngenerator.eval()  # Set the generator to evaluation mode\n\n# Generate and save images individually\ndef generate_and_save_individual_images(generator, latent_dim, output_dir=\"generated_images\", num_images=16):\n    os.makedirs(output_dir, exist_ok=True)  # Create directory to save images\n    for i in range(num_images):\n        z = torch.randn(1, latent_dim).to(device)  # Generate a single latent vector\n        with torch.no_grad():\n            gen_img = generator(z)  # Generate a single image\n        gen_img = (gen_img + 1) / 2  # Rescale to [0, 1]\n        gen_img = gen_img.cpu()  # Move to CPU\n        save_path = os.path.join(output_dir, f\"generated_image_{i + 1}.png\")\n        save_image(gen_img, save_path)  # Save the individual image\n        print(f\"Generated image saved to {save_path}\")\n\n\n# Generate and save the images\ngenerate_and_save_individual_images(generator, latent_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:26:06.333363Z","iopub.execute_input":"2025-01-31T04:26:06.333958Z","iopub.status.idle":"2025-01-31T04:26:07.062431Z","shell.execute_reply.started":"2025-01-31T04:26:06.333925Z","shell.execute_reply":"2025-01-31T04:26:07.061189Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-5-1c76b695ace9>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  generator.load_state_dict(torch.load(\"/kaggle/input/epoch-500-0.0001-2x-db-15-sample-10000/pytorch/v1/1/generator_epoch_500.pth\", map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Generated image saved to generated_images/generated_image_1.png\nGenerated image saved to generated_images/generated_image_2.png\nGenerated image saved to generated_images/generated_image_3.png\nGenerated image saved to generated_images/generated_image_4.png\nGenerated image saved to generated_images/generated_image_5.png\nGenerated image saved to generated_images/generated_image_6.png\nGenerated image saved to generated_images/generated_image_7.png\nGenerated image saved to generated_images/generated_image_8.png\nGenerated image saved to generated_images/generated_image_9.png\nGenerated image saved to generated_images/generated_image_10.png\nGenerated image saved to generated_images/generated_image_11.png\nGenerated image saved to generated_images/generated_image_12.png\nGenerated image saved to generated_images/generated_image_13.png\nGenerated image saved to generated_images/generated_image_14.png\nGenerated image saved to generated_images/generated_image_15.png\nGenerated image saved to generated_images/generated_image_16.png\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}